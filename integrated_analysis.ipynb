{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6360eb71-0003-429d-b76d-cabc77a1d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from math import inf\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d0a7dc-79f4-4298-bfb9-da41f87856ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. Core functions\n",
    "# ==========================================\n",
    "\n",
    "def softmax(x, beta=1.0):\n",
    "    \"\"\"\n",
    "    Softmax function with stability adjustment.\n",
    "    \"\"\"\n",
    "    # Subtract the maximum value to prevent index explosion\n",
    "    ex = np.exp(beta * (x - np.max(x)))\n",
    "    return ex / ex.sum()\n",
    "\n",
    "def calculate_bic(nll, n_params, n_observations):\n",
    "    \"\"\"Calculate Bayesian Information Criterion (BIC)\"\"\"\n",
    "    return 2 * nll + n_params * np.log(n_observations)\n",
    "\n",
    "def prepare_arrays_robust(sub_df):\n",
    "    \"\"\"\n",
    "    Data preprocessing: Ensure no NaN values, extract choices and rewards.\n",
    "    Compatible with categorizy_idx (1-4) or 0-3 indexes of RL_madel. py.\n",
    "    \"\"\"\n",
    "    # define col names\n",
    "    choice_col = 'category_idx' if 'category_idx' in sub_df.columns else 'choice'\n",
    "    reward_col = 'reward'\n",
    "    \n",
    "    # filter NaN\n",
    "    mask = ~sub_df[choice_col].isna() & ~sub_df[reward_col].isna()\n",
    "    clean_df = sub_df[mask].copy()\n",
    "    \n",
    "    choices = clean_df[choice_col].astype(int).values\n",
    "    rewards = clean_df[reward_col].astype(float).values\n",
    "    \n",
    "    \n",
    "    if choices.min() == 0:\n",
    "        choices = choices + 1\n",
    "        \n",
    "    return choices, rewards\n",
    "\n",
    "# ==========================================\n",
    "# 2. RL MODEL algorithms (Rescorla-Wagner)\n",
    "# ==========================================\n",
    "\n",
    "def negloglik_rl_robust(params, choices, rewards, n_options=4, q0=2.5):\n",
    "    \"\"\"\n",
    "    Negative log likelihood function:RL\n",
    "    Params: [alpha, log_beta] (use log_beta to make sure beta > 0)\n",
    "    \"\"\"\n",
    "    alpha, logbeta = params\n",
    "    \n",
    "    # Hard constraint check (although L-BFGS-B has boundaries, double insurance)\n",
    "    if not (0 <= alpha <= 1):\n",
    "        return 1e9\n",
    "        \n",
    "    beta = np.exp(logbeta) \n",
    "    Q = np.ones(n_options) * q0\n",
    "    nll = 0.0\n",
    "    \n",
    "    for c, r in zip(choices, rewards):\n",
    "        # c is 1-4, map to 0-3\n",
    "        c_idx = c - 1\n",
    "        \n",
    "        probs = softmax(Q, beta=beta)\n",
    "        p = probs[c_idx]\n",
    "        \n",
    "        # avoid log(0)\n",
    "        p = max(p, 1e-12)\n",
    "        nll -= np.log(p)\n",
    "        \n",
    "        # updata Q value\n",
    "        Q[c_idx] = Q[c_idx] + alpha * (r - Q[c_idx])\n",
    "        \n",
    "    return nll\n",
    "\n",
    "def fit_robust_rl_model(df):\n",
    "    \"\"\"\n",
    "    fit RL model\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"正在拟合模型: Robust Standard RL (Source: model_build_fit.py)...\")\n",
    "    results = []\n",
    "    \n",
    "    # Traverse each subject\n",
    "    \n",
    "    user_col = 'subject_id' if 'subject_id' in df.columns else 'user'\n",
    "    \n",
    "    for sub_id, sub_df in df.groupby(user_col):\n",
    "        choices, rewards = prepare_arrays_robust(sub_df)\n",
    "        \n",
    "        if len(choices) < 5: \n",
    "            continue\n",
    "\n",
    "        \n",
    "        x0 = np.array([0.3, np.log(1.0)])\n",
    "        \n",
    "        # bound: alpha [0, 1], beta [1e-3, 1e3] (log space)\n",
    "        bounds = [(0.0, 1.0), (np.log(1e-3), np.log(1e3))]\n",
    "        \n",
    "        # optimize\n",
    "        res = minimize(\n",
    "            lambda x: negloglik_rl_robust(x, choices, rewards), \n",
    "            x0, \n",
    "            bounds=bounds, \n",
    "            method='L-BFGS-B'\n",
    "        )\n",
    "        \n",
    "        if res.success:\n",
    "            alpha = res.x[0]\n",
    "            beta = float(np.exp(res.x[1])) \n",
    "            nll = res.fun\n",
    "        else:\n",
    "            alpha, beta, nll = np.nan, np.nan, np.nan\n",
    "            \n",
    "        # BIC (k=2: alpha, beta)\n",
    "        bic = calculate_bic(nll, 2, len(choices)) if not np.isnan(nll) else np.nan\n",
    "        \n",
    "        results.append({\n",
    "            'subject_id': sub_id,\n",
    "            'alpha': alpha,\n",
    "            'beta': beta,\n",
    "            'nll': nll,\n",
    "            'bic': bic\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ==========================================\n",
    "# 3. PT Model (Static Prospect Theory)\n",
    "# ==========================================\n",
    "\n",
    "def compute_empirical_category_distributions(df):\n",
    "    \"\"\"\n",
    "    Calculate the global empirical distribution (used for probability weighting in PT models)\n",
    "    \"\"\"\n",
    "    dists = {}\n",
    "    \n",
    "    cat_col = 'category_idx' if 'category_idx' in df.columns else 'cat'\n",
    "    \n",
    "    if df[cat_col].min() == 0:\n",
    "        df = df.copy()\n",
    "        df[cat_col] = df[cat_col] + 1\n",
    "    \n",
    "    for cat in [1, 2, 3, 4]:\n",
    "        vals = df[df[cat_col] == cat]['reward'].dropna().values\n",
    "        if len(vals) == 0:\n",
    "            dists[cat] = (np.array([0.0, 1.0]), np.array([0.0, 0.0]))\n",
    "        else:\n",
    "            unique, counts = np.unique(vals, return_counts=True)\n",
    "            probs = counts / counts.sum()\n",
    "            dists[cat] = (unique, probs)\n",
    "    return dists\n",
    "\n",
    "def prelec_weight(p, gamma):\n",
    "    \"\"\"Prelec (1998) probability weighting function\"\"\"\n",
    "    p = np.clip(p, 1e-12, 1.0)\n",
    "    return np.exp(-(-np.log(p)) ** gamma)\n",
    "\n",
    "def subjective_EV_for_category(cat, alpha_val, gamma_val, category_dists):\n",
    "    \"\"\"Calculate the subjective expected value adjusted by PT for a specific category\"\"\"\n",
    "    outcomes, probs = category_dists[cat]\n",
    "    \n",
    "    # Value function: u(x) = x^alpha\n",
    "    \n",
    "    u = outcomes ** alpha_val\n",
    "    \n",
    "    # Probability weighting\n",
    "    w = prelec_weight(probs, gamma_val)\n",
    "    \n",
    "    # Normalize weights (approximated)\n",
    "    if w.sum() == 0:\n",
    "        w = probs\n",
    "    else:\n",
    "        w = w / w.sum()\n",
    "        \n",
    "    return np.sum(w * u)\n",
    "\n",
    "def negloglik_pt_robust(params, choices, category_dists):\n",
    "    \"\"\"\n",
    "    nll：Static PT\n",
    "    Params: [log_alpha, log_gamma, log_beta]\n",
    "    \"\"\"\n",
    "    log_alpha, log_gamma, log_beta = params\n",
    "    \n",
    "    alpha_val = np.exp(log_alpha)\n",
    "    gamma_val = np.exp(log_gamma)\n",
    "    beta = np.exp(log_beta)\n",
    "    \n",
    "    # sEV\n",
    "    sEV = np.array([subjective_EV_for_category(cat, alpha_val, gamma_val, category_dists) \n",
    "                    for cat in [1, 2, 3, 4]])\n",
    "    \n",
    "    nll = 0.0\n",
    "    for c in choices:\n",
    "        c_idx = c - 1 # map 1-4 to 0-3\n",
    "        probs = softmax(sEV, beta=beta)\n",
    "        p = probs[c_idx]\n",
    "        p = max(p, 1e-12)\n",
    "        nll -= np.log(p)\n",
    "        \n",
    "    return nll\n",
    "\n",
    "def fit_robust_pt_model(df):\n",
    "    \"\"\"\n",
    "    fit Static PT model\n",
    "   \n",
    "    \"\"\"\n",
    "    print(\"正在拟合模型: Robust Static PT (Source: model_build_fit.py)...\")\n",
    "    results = []\n",
    "    \n",
    "    # 1.  (Pooled)\n",
    "    category_dists = compute_empirical_category_distributions(df)\n",
    "    \n",
    "    user_col = 'subject_id' if 'subject_id' in df.columns else 'user'\n",
    "    \n",
    "    for sub_id, sub_df in df.groupby(user_col):\n",
    "        choices, _ = prepare_arrays_robust(sub_df) # PT \n",
    "        \n",
    "        if len(choices) < 5:\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        x0 = np.array([np.log(0.9), np.log(0.9), np.log(1.0)])\n",
    "        \n",
    "        # Bounds (all in log space)\n",
    "        # alpha: [0.01, 5.0], gamma: [0.01, 5.0], beta: [0.001, 1000]\n",
    "        bounds = [\n",
    "            (np.log(1e-2), np.log(5.0)), \n",
    "            (np.log(1e-2), np.log(5.0)), \n",
    "            (np.log(1e-3), np.log(1e3))\n",
    "        ]\n",
    "        \n",
    "        res = minimize(\n",
    "            lambda x: negloglik_pt_robust(x, choices, category_dists),\n",
    "            x0,\n",
    "            bounds=bounds,\n",
    "            method='L-BFGS-B'\n",
    "        )\n",
    "        \n",
    "        if res.success:\n",
    "            alpha = float(np.exp(res.x[0]))\n",
    "            gamma = float(np.exp(res.x[1]))\n",
    "            beta = float(np.exp(res.x[2]))\n",
    "            nll = res.fun\n",
    "        else:\n",
    "            alpha, gamma, beta, nll = np.nan, np.nan, np.nan, np.nan\n",
    "            \n",
    "        # BIC (k=3: alpha, gamma, beta)\n",
    "        bic = calculate_bic(nll, 3, len(choices)) if not np.isnan(nll) else np.nan\n",
    "        \n",
    "        results.append({\n",
    "            'subject_id': sub_id,\n",
    "            'alpha': alpha,\n",
    "            'gamma': gamma,\n",
    "            'beta': beta,\n",
    "            'nll': nll,\n",
    "            'bic': bic\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 2. Model: RL + Prospect Theory (Robust Version)\n",
    "def fit_rl_pt(df):\n",
    "    print(\"正在拟合模型 2/4: RL + Prospect Theory (Robust) ...\")\n",
    "    results = []\n",
    "    GAMMA = 0.8\n",
    "    REF_POINT = 2.5\n",
    "    \n",
    "    # NLL: Params = [alpha, log_beta, log_lambda]\n",
    "    def get_nll_robust(params, choices, rewards):\n",
    "        alpha, log_beta, log_lamb = params\n",
    "        if not (0 <= alpha <= 1): return 1e9\n",
    "        \n",
    "        beta = np.exp(log_beta)\n",
    "        lamb = np.exp(log_lamb)\n",
    "        \n",
    "        q_values = np.full(4, 2.5)\n",
    "        nll = 0.0\n",
    "        \n",
    "        for c, r in zip(choices, rewards):\n",
    "            c_idx = int(c) - 1\n",
    "            # Softmax\n",
    "            probs = softmax(q_values, beta=beta)\n",
    "            nll -= np.log(max(probs[c_idx], 1e-12))\n",
    "            \n",
    "            # PT Utility\n",
    "            utility = (r - REF_POINT)**GAMMA if r >= REF_POINT else -lamb * ((REF_POINT - r)**GAMMA)\n",
    "            \n",
    "            # Update\n",
    "            q_values[c_idx] += alpha * (utility - q_values[c_idx])\n",
    "        return nll\n",
    "\n",
    "    for sub_id, sub_df in df.groupby('subject_id'):\n",
    "        choices, rewards = prepare_arrays_robust(sub_df)\n",
    "        if len(choices) < 5: continue\n",
    "        \n",
    "        # Initial: alpha=0.5, beta=2.0, lambda=1.0\n",
    "        x0 = [0.5, np.log(2.0), np.log(1.0)]\n",
    "        # Bounds: alpha[0,1], beta[0.001, 1000], lambda[0.001, 100]\n",
    "        bounds = [(0, 1), (np.log(1e-3), np.log(1e3)), (np.log(1e-3), np.log(1e2))]\n",
    "        \n",
    "        res = minimize(lambda x: get_nll_robust(x, choices, rewards), x0, bounds=bounds, method='L-BFGS-B')\n",
    "        \n",
    "        if res.success:\n",
    "            results.append({\n",
    "                'subject_id': sub_id,\n",
    "                'alpha': res.x[0],\n",
    "                'beta': np.exp(res.x[1]),\n",
    "                'lambda': np.exp(res.x[2]),\n",
    "                'nll': res.fun,\n",
    "                'bic': calculate_bic(res.fun, 3, len(choices))\n",
    "            })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 3. Model: Hybrid RL + Likeability (Robust Version)\n",
    "def fit_hybrid_likeability(df):\n",
    "    print(\"正在拟合模型 3/4: Hybrid RL + Likeability (Robust) ...\")\n",
    "    \n",
    "    # normalize Likeability \n",
    "    df_std = df.copy()\n",
    "    like_cols = ['like_cat1', 'like_cat2', 'like_cat3', 'like_cat4']\n",
    "    for sub_id, group in df_std.groupby('subject_id'):\n",
    "        vals = group[like_cols].values.flatten()\n",
    "        std_val = np.nanstd(vals)\n",
    "        if std_val == 0: std_val = 1\n",
    "        df_std.loc[df_std['subject_id'] == sub_id, like_cols] = (group[like_cols] - np.nanmean(vals)) / std_val\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # NLL: Params = [alpha, log_beta, omega]\n",
    "    def get_nll_robust(params, choices, rewards, like_matrix):\n",
    "        alpha, log_beta, omega = params\n",
    "        if not (0 <= alpha <= 1): return 1e9\n",
    "        \n",
    "        beta = np.exp(log_beta)\n",
    "        q_values = np.full(4, 2.5)\n",
    "        nll = 0.0\n",
    "        \n",
    "        for i, (c, r) in enumerate(zip(choices, rewards)):\n",
    "            c_idx = int(c) - 1\n",
    "            likes = like_matrix[i]\n",
    "            \n",
    "            # V = beta*Q + omega*L\n",
    "            v_values = (beta * q_values) + (omega * likes)\n",
    "            \n",
    "            probs = softmax(v_values, beta=1.0) \n",
    "            nll -= np.log(max(probs[c_idx], 1e-12))\n",
    "            \n",
    "            q_values[c_idx] += alpha * (r - q_values[c_idx])\n",
    "        return nll\n",
    "\n",
    "    for sub_id, sub_df in df_std.groupby('subject_id'):\n",
    "        choices, rewards = prepare_arrays_robust(sub_df)\n",
    "        if len(choices) < 5: continue\n",
    "        \n",
    "        like_matrix = sub_df[like_cols].values\n",
    "       \n",
    "        if len(like_matrix) != len(choices):\n",
    "            \n",
    "            mask = ~sub_df['category_idx'].isna() & ~sub_df['reward'].isna()\n",
    "            like_matrix = sub_df.loc[mask, like_cols].values\n",
    "            \n",
    "        x0 = [0.5, np.log(2.0), 0.5]\n",
    "        bounds = [(0, 1), (np.log(1e-3), np.log(1e3)), (-10, 10)]\n",
    "        \n",
    "        res = minimize(lambda x: get_nll_robust(x, choices, rewards, like_matrix), x0, bounds=bounds, method='L-BFGS-B')\n",
    "        \n",
    "        if res.success:\n",
    "            results.append({\n",
    "                'subject_id': sub_id,\n",
    "                'alpha': res.x[0],\n",
    "                'beta': np.exp(res.x[1]),\n",
    "                'omega': res.x[2],\n",
    "                'nll': res.fun,\n",
    "                'bic': calculate_bic(res.fun, 3, len(choices))\n",
    "            })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 4.  RL with Perseveration (Robust Version)\n",
    "def fit_perseveration_rl(df):\n",
    "    print(\"正在拟合模型 4/4: RL with Perseveration (Robust) ...\")\n",
    "    results = []\n",
    "    \n",
    "    # NLL: Params = [alpha, log_beta, kappa] \n",
    "    def get_nll_robust(params, choices, rewards):\n",
    "        alpha, log_beta, kappa = params\n",
    "        if not (0 <= alpha <= 1): return 1e9\n",
    "        \n",
    "        beta = np.exp(log_beta)\n",
    "        q_values = np.full(4, 2.5)\n",
    "        nll = 0.0\n",
    "        prev_choice = -1\n",
    "        \n",
    "        for c, r in zip(choices, rewards):\n",
    "            c_idx = int(c) - 1\n",
    "            \n",
    "            # V = beta*Q + kappa*I\n",
    "            v_values = beta * q_values\n",
    "            if prev_choice != -1:\n",
    "                v_values[prev_choice] += kappa\n",
    "            \n",
    "            probs = softmax(v_values, beta=1.0)\n",
    "            nll -= np.log(max(probs[c_idx], 1e-12))\n",
    "            \n",
    "            q_values[c_idx] += alpha * (r - q_values[c_idx])\n",
    "            prev_choice = c_idx\n",
    "        return nll\n",
    "\n",
    "    for sub_id, sub_df in df.groupby('subject_id'):\n",
    "        choices, rewards = prepare_arrays_robust(sub_df)\n",
    "        if len(choices) < 5: continue\n",
    "        \n",
    "        x0 = [0.5, np.log(2.0), 0.5]\n",
    "        bounds = [(0, 1), (np.log(1e-3), np.log(1e3)), (-5, 5)]\n",
    "        \n",
    "        res = minimize(lambda x: get_nll_robust(x, choices, rewards), x0, bounds=bounds, method='L-BFGS-B')\n",
    "        \n",
    "        if res.success:\n",
    "            results.append({\n",
    "                'subject_id': sub_id,\n",
    "                'alpha': res.x[0],\n",
    "                'beta': np.exp(res.x[1]),\n",
    "                'kappa': res.x[2],\n",
    "                'nll': res.fun,\n",
    "                'bic': calculate_bic(res.fun, 3, len(choices))\n",
    "            })\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705c377d-84ef-4d76-a75e-9f94deab03c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在拟合模型: Robust Standard RL (Source: model_build_fit.py)...\n",
      "正在拟合模型 2/4: RL + Prospect Theory (Robust) ...\n",
      "正在拟合模型: Robust Static PT (Source: model_build_fit.py)...\n",
      "正在拟合模型 3/4: Hybrid RL + Likeability (Robust) ...\n",
      "正在拟合模型 4/4: RL with Perseveration (Robust) ...\n"
     ]
    }
   ],
   "source": [
    "df_master = pd.read_csv('02_Master_df.csv')\n",
    "df_standard_rl = fit_robust_rl_model(df_master)\n",
    "df_rl_pt = fit_rl_pt(df_master)\n",
    "df_pt = fit_robust_pt_model(df_master)\n",
    "df_hybrid = fit_hybrid_likeability(df_master)\n",
    "df_perseveration = fit_perseveration_rl(df_master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316338db-8be6-4d4f-ab78-c8c7afdf4cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Save the result\n",
    "# ------------------------------------------------\n",
    "output_dir = 'D:/Development/Data/BCAI/PCA/RL_results'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "df_standard_rl.to_csv(os.path.join(output_dir, '00_RL.csv'), index=False)\n",
    "df_rl_pt.to_csv(os.path.join(output_dir, '01_RL_PT1.csv'), index=False)\n",
    "df_hybrid.to_csv(os.path.join(output_dir, '02_hybrid.csv'), index=False)\n",
    "df_perseveration.to_csv(os.path.join(output_dir, '03_Pres.csv'), index=False)\n",
    "df_pt.to_csv(os.path.join(output_dir, '01.1_RL_PT2.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bb7253-6a25-42e0-ba53-9ed7c2b3cd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取启发式数据: D:/Development/Data/BCAI/PCA\\04_heuristic_results2.csv\n",
      "\n",
      "结果预览:\n",
      "     subject_id           model         bic        nll\n",
      "38            1  RL+Likeability   75.199595  32.066478\n",
      "39            2  RL+Likeability   95.033009  42.021162\n",
      "40            3  RL+Likeability   99.308595  44.120978\n",
      "154           4         gambler  101.313744        NaN\n",
      "117           5              cw   82.893063        NaN\n",
      "43            6  RL+Likeability  104.770192  46.851777\n",
      "44            7  RL+Likeability   88.761311  38.847336\n",
      "45            8  RL+Likeability  110.076510  49.504936\n",
      "46            9  RL+Likeability   96.001722  42.467542\n",
      "65           10              PT  100.962717  44.948040\n",
      "\n",
      "最优模型结果已保存至: D:/Development/Data/BCAI/PCA\\09_best_fitting_models.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "base_dir = 'D:/Development/Data/BCAI/PCA'\n",
    "heuristic_file = os.path.join(base_dir, '04_heuristic_results2.csv')\n",
    "\n",
    "output_dir = 'D:/Development/Data/BCAI/PCA/RL_results'\n",
    "output_file = os.path.join(base_dir, '09_best_fitting_models.csv')\n",
    "\n",
    "\n",
    "# 2. Integrate all results\n",
    "all_results = []\n",
    "ml_dfs = {\n",
    "    'RL': df_standard_rl,\n",
    "    'RL_PT': df_rl_pt,\n",
    "    'RL+Likeability': df_hybrid,\n",
    "    'PT':df_pt\n",
    "}\n",
    "\n",
    "for name, df in ml_dfs.items():\n",
    "    if not df.empty:\n",
    "        temp = df[['subject_id', 'bic', 'nll']].copy()\n",
    "        temp['model'] = name\n",
    "        all_results.append(temp)\n",
    "\n",
    "# 3. deal with heuristic data\n",
    "print(f\"读取启发式数据: {heuristic_file}\")\n",
    "try:\n",
    "    heuristic_df = pd.read_csv(heuristic_file)\n",
    "    \n",
    "    \n",
    "    id_vars = ['subject_id']\n",
    "    value_vars = [c for c in heuristic_df.columns if c not in id_vars and 'unnamed' not in c.lower()]\n",
    "    \n",
    "    \n",
    "    heuristic_melted = heuristic_df.melt(id_vars=id_vars, value_vars=value_vars, var_name='model_col', value_name='bic')\n",
    "    \n",
    "    \n",
    "    heuristic_melted['model'] = heuristic_melted['model_col'].str.replace('bic_', '', regex=False)\n",
    "    heuristic_melted['nll'] = np.nan \n",
    "    \n",
    "    heuristic_final = heuristic_melted[['subject_id', 'bic', 'nll', 'model']]\n",
    "    all_results.append(heuristic_final)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"警告: 未找到启发式结果文件，将只比较 RL 模型。\")\n",
    "\n",
    "# 4. 合并与比较\n",
    "combined_df = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "# 找出 BIC 最小的模型\n",
    "best_models = combined_df.loc[combined_df.groupby('subject_id')['bic'].idxmin()].copy()\n",
    "best_models = best_models.sort_values('subject_id')[['subject_id', 'model', 'bic', 'nll']]\n",
    "\n",
    "# 5. 保存结果\n",
    "print(\"\\n结果预览:\")\n",
    "print(best_models.head(10))\n",
    "\n",
    "best_models.to_csv(output_file, index=False)\n",
    "print(f\"\\n最优模型结果已保存至: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4a55ee3-48de-4a66-bc54-75836dd5a7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     subject_id           model         bic        nll\n",
      "38            1  RL+Likeability   75.199595  32.066478\n",
      "39            2  RL+Likeability   95.033009  42.021162\n",
      "40            3  RL+Likeability   99.308595  44.120978\n",
      "154           4         gambler  101.313744        NaN\n",
      "117           5              cw   82.893063        NaN\n",
      "43            6  RL+Likeability  104.770192  46.851777\n",
      "44            7  RL+Likeability   88.761311  38.847336\n",
      "45            8  RL+Likeability  110.076510  49.504936\n",
      "46            9  RL+Likeability   96.001722  42.467542\n",
      "65           10              PT  100.962717  44.948040\n",
      "48           11  RL+Likeability  105.846028  47.389695\n",
      "11           12              RL  103.419557  48.020899\n",
      "49           13  RL+Likeability   91.131848  40.032605\n",
      "69           14              PT  100.987264  44.960313\n",
      "70           15              PT  104.713770  46.823566\n",
      "90           16            like   18.420681        NaN\n",
      "16           17              RL  104.555257  48.588749\n",
      "54           18  RL+Likeability   84.490242  36.711802\n",
      "18           19              RL  114.901392  53.761816\n"
     ]
    }
   ],
   "source": [
    "print(best_models.head(19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29955b21-6970-4b43-a965-65b02a60181c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在拟合模型: Robust Standard RL with Statistics...\n",
      "正在拟合模型: Robust Static PT with Statistics...\n",
      "正在拟合模型: RL + Prospect Theory with Statistics...\n",
      "正在拟合模型: Hybrid RL + Likeability with Statistics...\n",
      "正在拟合模型: RL with Perseveration with Statistics...\n",
      "\n",
      "============================================================\n",
      "MODEL COMPARISON SUMMARY\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Model: Standard RL\n",
      "============================================================\n",
      "Parameter     Mean        SE        z        P Sig\n",
      "    alpha 0.145902  0.343329 0.424964 0.670863    \n",
      "     beta 3.328163 44.504978 0.074782 0.940388    \n",
      "\n",
      "N subjects: 19\n",
      "Mean BIC: 107.73\n",
      "Mean NLL: 50.18\n",
      "\n",
      "============================================================\n",
      "Model: Static Prospect Theory\n",
      "============================================================\n",
      "Parameter      Mean         SE        z        P Sig\n",
      "    alpha  2.396867   9.553485 0.250889 0.801900    \n",
      "    gamma  1.218326   3.063365 0.397708 0.690845    \n",
      "     beta 11.792968 567.765370 0.020771 0.983428    \n",
      "\n",
      "N subjects: 19\n",
      "Mean BIC: 107.56\n",
      "Mean NLL: 48.25\n",
      "\n",
      "============================================================\n",
      "Model: RL + Prospect Theory\n",
      "============================================================\n",
      "Parameter      Mean         SE        z        P Sig\n",
      "    alpha  0.395156   0.086960 4.544122 0.000006 ***\n",
      "     beta  0.412228   0.794691 0.518728 0.603951    \n",
      "   lambda 10.596418 356.864522 0.029693 0.976312    \n",
      "\n",
      "N subjects: 19\n",
      "Mean BIC: 118.24\n",
      "Mean NLL: 53.59\n",
      "\n",
      "============================================================\n",
      "Model: Hybrid RL + Likeability\n",
      "============================================================\n",
      "Parameter       Mean          SE        z        P Sig\n",
      "    alpha   0.184222    0.216285 0.851754 0.394350    \n",
      "     beta 101.325841 2825.157906 0.035866 0.971390    \n",
      "    omega   0.672105  242.535779 0.002771 0.997789    \n",
      "\n",
      "N subjects: 17\n",
      "Mean BIC: 100.64\n",
      "Mean NLL: 44.79\n",
      "\n",
      "============================================================\n",
      "Model: RL + Perseveration\n",
      "============================================================\n",
      "Parameter       Mean          SE         z        P Sig\n",
      "    alpha   0.119138    0.198635  0.599782 0.548652    \n",
      "     beta 126.207357 3873.518372  0.032582 0.974008    \n",
      "    kappa  -0.431500    0.429273 -1.005190 0.314806    \n",
      "\n",
      "N subjects: 19\n",
      "Mean BIC: 108.89\n",
      "Mean NLL: 48.91\n",
      "\n",
      "✓ Results saved to CSV and Excel files\n"
     ]
    }
   ],
   "source": [
    "############################################Check the significance of parameters (calculate SE and p values)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "# ==========================================\n",
    "# Enhanced Helper Functions with SE/P-value calculation\n",
    "# ==========================================\n",
    "df_master = pd.read_csv('02_Master_df.csv')\n",
    "\n",
    "def calculate_se_pvalues(res, nll_func, choices, rewards=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Calculate standard errors and p-values using Hessian matrix\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    res : OptimizeResult\n",
    "        Result from scipy.optimize.minimize\n",
    "    nll_func : callable\n",
    "        Negative log-likelihood function\n",
    "    choices : array\n",
    "        Choice data\n",
    "    rewards : array, optional\n",
    "        Reward data (for RL models)\n",
    "    **kwargs : dict\n",
    "        Additional arguments for nll_func (e.g., category_dists, like_matrix)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    se_dict : dict\n",
    "        Dictionary of standard errors for each parameter\n",
    "    pval_dict : dict\n",
    "        Dictionary of p-values for each parameter\n",
    "    \"\"\"\n",
    "    if not res.success:\n",
    "        return {}, {}\n",
    "    \n",
    "    # Compute Hessian using finite differences\n",
    "    params = res.x\n",
    "    epsilon = 1e-5\n",
    "    n_params = len(params)\n",
    "    hessian = np.zeros((n_params, n_params))\n",
    "    \n",
    "    # Prepare arguments for nll_func\n",
    "    if rewards is not None:\n",
    "        args = (choices, rewards)\n",
    "    else:\n",
    "        args = (choices,)\n",
    "    \n",
    "    # Add kwargs if present\n",
    "    for key, value in kwargs.items():\n",
    "        args = args + (value,)\n",
    "    \n",
    "    # Compute Hessian numerically\n",
    "    for i in range(n_params):\n",
    "        for j in range(n_params):\n",
    "            params_pp = params.copy()\n",
    "            params_pm = params.copy()\n",
    "            params_mp = params.copy()\n",
    "            params_mm = params.copy()\n",
    "            \n",
    "            params_pp[i] += epsilon\n",
    "            params_pp[j] += epsilon\n",
    "            params_pm[i] += epsilon\n",
    "            params_pm[j] -= epsilon\n",
    "            params_mp[i] -= epsilon\n",
    "            params_mp[j] += epsilon\n",
    "            params_mm[i] -= epsilon\n",
    "            params_mm[j] -= epsilon\n",
    "            \n",
    "            hessian[i, j] = (\n",
    "                nll_func(params_pp, *args) - \n",
    "                nll_func(params_pm, *args) - \n",
    "                nll_func(params_mp, *args) + \n",
    "                nll_func(params_mm, *args)\n",
    "            ) / (4 * epsilon ** 2)\n",
    "    \n",
    "    # Calculate variance-covariance matrix (inverse of Hessian)\n",
    "    try:\n",
    "        # Add small ridge to diagonal for numerical stability\n",
    "        hessian_stable = hessian + np.eye(n_params) * 1e-6\n",
    "        var_cov = np.linalg.inv(hessian_stable)\n",
    "        se = np.sqrt(np.diag(var_cov))\n",
    "        \n",
    "        # Calculate z-scores and p-values (two-tailed test)\n",
    "        z_scores = params / se\n",
    "        p_values = 2 * (1 - norm.cdf(np.abs(z_scores)))\n",
    "        \n",
    "    except np.linalg.LinAlgError:\n",
    "        # If Hessian is singular, return NaN\n",
    "        se = np.full(n_params, np.nan)\n",
    "        p_values = np.full(n_params, np.nan)\n",
    "    \n",
    "    return se, p_values\n",
    "\n",
    "def format_significance(p_value):\n",
    "    \"\"\"Format p-value with significance stars\"\"\"\n",
    "    if np.isnan(p_value):\n",
    "        return ''\n",
    "    elif p_value < 0.001:\n",
    "        return '***'\n",
    "    elif p_value < 0.01:\n",
    "        return '**'\n",
    "    elif p_value < 0.05:\n",
    "        return '*'\n",
    "    elif p_value < 0.1:\n",
    "        return '+'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# ==========================================\n",
    "# Modified RL Model with SE/P-values\n",
    "# ==========================================\n",
    "\n",
    "def fit_robust_rl_model_with_stats(df):\n",
    "    \"\"\"\n",
    "    Fit RL model with standard errors and p-values\n",
    "    \"\"\"\n",
    "    print(\"正在拟合模型: Robust Standard RL with Statistics...\")\n",
    "    results = []\n",
    "    \n",
    "    user_col = 'subject_id' if 'subject_id' in df.columns else 'user'\n",
    "    \n",
    "    for sub_id, sub_df in df.groupby(user_col):\n",
    "        choices, rewards = prepare_arrays_robust(sub_df)\n",
    "        \n",
    "        if len(choices) < 5:\n",
    "            continue\n",
    "\n",
    "        x0 = np.array([0.3, np.log(1.0)])\n",
    "        bounds = [(0.0, 1.0), (np.log(1e-3), np.log(1e3))]\n",
    "        \n",
    "        res = minimize(\n",
    "            lambda x: negloglik_rl_robust(x, choices, rewards), \n",
    "            x0, \n",
    "            bounds=bounds, \n",
    "            method='L-BFGS-B'\n",
    "        )\n",
    "        \n",
    "        if res.success:\n",
    "            # Calculate SE and p-values\n",
    "            se, p_values = calculate_se_pvalues(\n",
    "                res, negloglik_rl_robust, choices, rewards\n",
    "            )\n",
    "            \n",
    "            # Transform parameters back\n",
    "            alpha = res.x[0]\n",
    "            beta = float(np.exp(res.x[1]))\n",
    "            nll = res.fun\n",
    "            \n",
    "            # SE for transformed parameters\n",
    "            # For beta: SE(beta) ≈ beta * SE(log_beta) (delta method)\n",
    "            se_alpha = se[0] if not np.isnan(se[0]) else np.nan\n",
    "            se_beta = beta * se[1] if not np.isnan(se[1]) else np.nan\n",
    "            \n",
    "            p_alpha = p_values[0]\n",
    "            p_beta = p_values[1]\n",
    "            \n",
    "        else:\n",
    "            alpha, beta, nll = np.nan, np.nan, np.nan\n",
    "            se_alpha, se_beta = np.nan, np.nan\n",
    "            p_alpha, p_beta = np.nan, np.nan\n",
    "            \n",
    "        bic = calculate_bic(nll, 2, len(choices)) if not np.isnan(nll) else np.nan\n",
    "        \n",
    "        results.append({\n",
    "            'subject_id': sub_id,\n",
    "            'alpha': alpha,\n",
    "            'alpha_se': se_alpha,\n",
    "            'alpha_p': p_alpha,\n",
    "            'alpha_sig': format_significance(p_alpha),\n",
    "            'beta': beta,\n",
    "            'beta_se': se_beta,\n",
    "            'beta_p': p_beta,\n",
    "            'beta_sig': format_significance(p_beta),\n",
    "            'nll': nll,\n",
    "            'bic': bic,\n",
    "            'n_trials': len(choices)\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ==========================================\n",
    "# Modified PT Model with SE/P-values\n",
    "# ==========================================\n",
    "\n",
    "def fit_robust_pt_model_with_stats(df):\n",
    "    \"\"\"\n",
    "    Fit Static PT model with standard errors and p-values\n",
    "    \"\"\"\n",
    "    print(\"正在拟合模型: Robust Static PT with Statistics...\")\n",
    "    results = []\n",
    "    \n",
    "    category_dists = compute_empirical_category_distributions(df)\n",
    "    user_col = 'subject_id' if 'subject_id' in df.columns else 'user'\n",
    "    \n",
    "    for sub_id, sub_df in df.groupby(user_col):\n",
    "        choices, _ = prepare_arrays_robust(sub_df)\n",
    "        \n",
    "        if len(choices) < 5:\n",
    "            continue\n",
    "            \n",
    "        x0 = np.array([np.log(0.9), np.log(0.9), np.log(1.0)])\n",
    "        bounds = [\n",
    "            (np.log(1e-2), np.log(5.0)), \n",
    "            (np.log(1e-2), np.log(5.0)), \n",
    "            (np.log(1e-3), np.log(1e3))\n",
    "        ]\n",
    "        \n",
    "        res = minimize(\n",
    "            lambda x: negloglik_pt_robust(x, choices, category_dists),\n",
    "            x0,\n",
    "            bounds=bounds,\n",
    "            method='L-BFGS-B'\n",
    "        )\n",
    "        \n",
    "        if res.success:\n",
    "            # Calculate SE and p-values\n",
    "            se, p_values = calculate_se_pvalues(\n",
    "                res, negloglik_pt_robust, choices, \n",
    "                category_dists=category_dists\n",
    "            )\n",
    "            \n",
    "            # Transform parameters\n",
    "            alpha = float(np.exp(res.x[0]))\n",
    "            gamma = float(np.exp(res.x[1]))\n",
    "            beta = float(np.exp(res.x[2]))\n",
    "            nll = res.fun\n",
    "            \n",
    "            # SE for transformed parameters (delta method)\n",
    "            se_alpha = alpha * se[0] if not np.isnan(se[0]) else np.nan\n",
    "            se_gamma = gamma * se[1] if not np.isnan(se[1]) else np.nan\n",
    "            se_beta = beta * se[2] if not np.isnan(se[2]) else np.nan\n",
    "            \n",
    "            p_alpha = p_values[0]\n",
    "            p_gamma = p_values[1]\n",
    "            p_beta = p_values[2]\n",
    "            \n",
    "        else:\n",
    "            alpha, gamma, beta, nll = np.nan, np.nan, np.nan, np.nan\n",
    "            se_alpha, se_gamma, se_beta = np.nan, np.nan, np.nan\n",
    "            p_alpha, p_gamma, p_beta = np.nan, np.nan, np.nan\n",
    "            \n",
    "        bic = calculate_bic(nll, 3, len(choices)) if not np.isnan(nll) else np.nan\n",
    "        \n",
    "        results.append({\n",
    "            'subject_id': sub_id,\n",
    "            'alpha': alpha,\n",
    "            'alpha_se': se_alpha,\n",
    "            'alpha_p': p_alpha,\n",
    "            'alpha_sig': format_significance(p_alpha),\n",
    "            'gamma': gamma,\n",
    "            'gamma_se': se_gamma,\n",
    "            'gamma_p': p_gamma,\n",
    "            'gamma_sig': format_significance(p_gamma),\n",
    "            'beta': beta,\n",
    "            'beta_se': se_beta,\n",
    "            'beta_p': p_beta,\n",
    "            'beta_sig': format_significance(p_beta),\n",
    "            'nll': nll,\n",
    "            'bic': bic,\n",
    "            'n_trials': len(choices)\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ==========================================\n",
    "# Modified RL+PT Model with SE/P-values\n",
    "# ==========================================\n",
    "\n",
    "def fit_rl_pt_with_stats(df):\n",
    "    \"\"\"Fit RL + Prospect Theory with statistics\"\"\"\n",
    "    print(\"正在拟合模型: RL + Prospect Theory with Statistics...\")\n",
    "    results = []\n",
    "    GAMMA = 0.8\n",
    "    REF_POINT = 2.5\n",
    "    \n",
    "    def get_nll_robust(params, choices, rewards):\n",
    "        alpha, log_beta, log_lamb = params\n",
    "        if not (0 <= alpha <= 1): return 1e9\n",
    "        \n",
    "        beta = np.exp(log_beta)\n",
    "        lamb = np.exp(log_lamb)\n",
    "        \n",
    "        q_values = np.full(4, 2.5)\n",
    "        nll = 0.0\n",
    "        \n",
    "        for c, r in zip(choices, rewards):\n",
    "            c_idx = int(c) - 1\n",
    "            probs = softmax(q_values, beta=beta)\n",
    "            nll -= np.log(max(probs[c_idx], 1e-12))\n",
    "            \n",
    "            utility = (r - REF_POINT)**GAMMA if r >= REF_POINT else -lamb * ((REF_POINT - r)**GAMMA)\n",
    "            q_values[c_idx] += alpha * (utility - q_values[c_idx])\n",
    "        return nll\n",
    "\n",
    "    for sub_id, sub_df in df.groupby('subject_id'):\n",
    "        choices, rewards = prepare_arrays_robust(sub_df)\n",
    "        if len(choices) < 5: continue\n",
    "        \n",
    "        x0 = [0.5, np.log(2.0), np.log(1.0)]\n",
    "        bounds = [(0, 1), (np.log(1e-3), np.log(1e3)), (np.log(1e-3), np.log(1e2))]\n",
    "        \n",
    "        res = minimize(lambda x: get_nll_robust(x, choices, rewards), x0, bounds=bounds, method='L-BFGS-B')\n",
    "        \n",
    "        if res.success:\n",
    "            se, p_values = calculate_se_pvalues(res, get_nll_robust, choices, rewards)\n",
    "            \n",
    "            alpha = res.x[0]\n",
    "            beta = np.exp(res.x[1])\n",
    "            lamb = np.exp(res.x[2])\n",
    "            \n",
    "            se_alpha = se[0]\n",
    "            se_beta = beta * se[1]\n",
    "            se_lambda = lamb * se[2]\n",
    "            \n",
    "            results.append({\n",
    "                'subject_id': sub_id,\n",
    "                'alpha': alpha,\n",
    "                'alpha_se': se_alpha,\n",
    "                'alpha_p': p_values[0],\n",
    "                'alpha_sig': format_significance(p_values[0]),\n",
    "                'beta': beta,\n",
    "                'beta_se': se_beta,\n",
    "                'beta_p': p_values[1],\n",
    "                'beta_sig': format_significance(p_values[1]),\n",
    "                'lambda': lamb,\n",
    "                'lambda_se': se_lambda,\n",
    "                'lambda_p': p_values[2],\n",
    "                'lambda_sig': format_significance(p_values[2]),\n",
    "                'nll': res.fun,\n",
    "                'bic': calculate_bic(res.fun, 3, len(choices)),\n",
    "                'n_trials': len(choices)\n",
    "            })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ==========================================\n",
    "# Modified Hybrid Model with SE/P-values\n",
    "# ==========================================\n",
    "\n",
    "def fit_hybrid_likeability_with_stats(df):\n",
    "    \"\"\"Fit Hybrid RL + Likeability with statistics\"\"\"\n",
    "    print(\"正在拟合模型: Hybrid RL + Likeability with Statistics...\")\n",
    "    \n",
    "    df_std = df.copy()\n",
    "    like_cols = ['like_cat1', 'like_cat2', 'like_cat3', 'like_cat4']\n",
    "    for sub_id, group in df_std.groupby('subject_id'):\n",
    "        vals = group[like_cols].values.flatten()\n",
    "        std_val = np.nanstd(vals)\n",
    "        if std_val == 0: std_val = 1\n",
    "        df_std.loc[df_std['subject_id'] == sub_id, like_cols] = (group[like_cols] - np.nanmean(vals)) / std_val\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    def get_nll_robust(params, choices, rewards, like_matrix):\n",
    "        alpha, log_beta, omega = params\n",
    "        if not (0 <= alpha <= 1): return 1e9\n",
    "        \n",
    "        beta = np.exp(log_beta)\n",
    "        q_values = np.full(4, 2.5)\n",
    "        nll = 0.0\n",
    "        \n",
    "        for i, (c, r) in enumerate(zip(choices, rewards)):\n",
    "            c_idx = int(c) - 1\n",
    "            likes = like_matrix[i]\n",
    "            \n",
    "            v_values = (beta * q_values) + (omega * likes)\n",
    "            probs = softmax(v_values, beta=1.0)\n",
    "            nll -= np.log(max(probs[c_idx], 1e-12))\n",
    "            \n",
    "            q_values[c_idx] += alpha * (r - q_values[c_idx])\n",
    "        return nll\n",
    "\n",
    "    for sub_id, sub_df in df_std.groupby('subject_id'):\n",
    "        choices, rewards = prepare_arrays_robust(sub_df)\n",
    "        if len(choices) < 5: continue\n",
    "        \n",
    "        mask = ~sub_df['category_idx'].isna() & ~sub_df['reward'].isna()\n",
    "        like_matrix = sub_df.loc[mask, like_cols].values\n",
    "            \n",
    "        x0 = [0.5, np.log(2.0), 0.5]\n",
    "        bounds = [(0, 1), (np.log(1e-3), np.log(1e3)), (-10, 10)]\n",
    "        \n",
    "        res = minimize(lambda x: get_nll_robust(x, choices, rewards, like_matrix), x0, bounds=bounds, method='L-BFGS-B')\n",
    "        \n",
    "        if res.success:\n",
    "            se, p_values = calculate_se_pvalues(res, get_nll_robust, choices, rewards, like_matrix=like_matrix)\n",
    "            \n",
    "            alpha = res.x[0]\n",
    "            beta = np.exp(res.x[1])\n",
    "            omega = res.x[2]\n",
    "            \n",
    "            se_alpha = se[0]\n",
    "            se_beta = beta * se[1]\n",
    "            se_omega = se[2]\n",
    "            \n",
    "            results.append({\n",
    "                'subject_id': sub_id,\n",
    "                'alpha': alpha,\n",
    "                'alpha_se': se_alpha,\n",
    "                'alpha_p': p_values[0],\n",
    "                'alpha_sig': format_significance(p_values[0]),\n",
    "                'beta': beta,\n",
    "                'beta_se': se_beta,\n",
    "                'beta_p': p_values[1],\n",
    "                'beta_sig': format_significance(p_values[1]),\n",
    "                'omega': omega,\n",
    "                'omega_se': se_omega,\n",
    "                'omega_p': p_values[2],\n",
    "                'omega_sig': format_significance(p_values[2]),\n",
    "                'nll': res.fun,\n",
    "                'bic': calculate_bic(res.fun, 3, len(choices)),\n",
    "                'n_trials': len(choices)\n",
    "            })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ==========================================\n",
    "# Modified Perseveration Model with SE/P-values\n",
    "# ==========================================\n",
    "\n",
    "def fit_perseveration_rl_with_stats(df):\n",
    "    \"\"\"Fit RL with Perseveration with statistics\"\"\"\n",
    "    print(\"正在拟合模型: RL with Perseveration with Statistics...\")\n",
    "    results = []\n",
    "    \n",
    "    def get_nll_robust(params, choices, rewards):\n",
    "        alpha, log_beta, kappa = params\n",
    "        if not (0 <= alpha <= 1): return 1e9\n",
    "        \n",
    "        beta = np.exp(log_beta)\n",
    "        q_values = np.full(4, 2.5)\n",
    "        nll = 0.0\n",
    "        prev_choice = -1\n",
    "        \n",
    "        for c, r in zip(choices, rewards):\n",
    "            c_idx = int(c) - 1\n",
    "            \n",
    "            v_values = beta * q_values\n",
    "            if prev_choice != -1:\n",
    "                v_values[prev_choice] += kappa\n",
    "            \n",
    "            probs = softmax(v_values, beta=1.0)\n",
    "            nll -= np.log(max(probs[c_idx], 1e-12))\n",
    "            \n",
    "            q_values[c_idx] += alpha * (r - q_values[c_idx])\n",
    "            prev_choice = c_idx\n",
    "        return nll\n",
    "\n",
    "    for sub_id, sub_df in df.groupby('subject_id'):\n",
    "        choices, rewards = prepare_arrays_robust(sub_df)\n",
    "        if len(choices) < 5: continue\n",
    "        \n",
    "        x0 = [0.5, np.log(2.0), 0.5]\n",
    "        bounds = [(0, 1), (np.log(1e-3), np.log(1e3)), (-5, 5)]\n",
    "        \n",
    "        res = minimize(lambda x: get_nll_robust(x, choices, rewards), x0, bounds=bounds, method='L-BFGS-B')\n",
    "        \n",
    "        if res.success:\n",
    "            se, p_values = calculate_se_pvalues(res, get_nll_robust, choices, rewards)\n",
    "            \n",
    "            alpha = res.x[0]\n",
    "            beta = np.exp(res.x[1])\n",
    "            kappa = res.x[2]\n",
    "            \n",
    "            se_alpha = se[0]\n",
    "            se_beta = beta * se[1]\n",
    "            se_kappa = se[2]\n",
    "            \n",
    "            results.append({\n",
    "                'subject_id': sub_id,\n",
    "                'alpha': alpha,\n",
    "                'alpha_se': se_alpha,\n",
    "                'alpha_p': p_values[0],\n",
    "                'alpha_sig': format_significance(p_values[0]),\n",
    "                'beta': beta,\n",
    "                'beta_se': se_beta,\n",
    "                'beta_p': p_values[1],\n",
    "                'beta_sig': format_significance(p_values[1]),\n",
    "                'kappa': kappa,\n",
    "                'kappa_se': se_kappa,\n",
    "                'kappa_p': p_values[2],\n",
    "                'kappa_sig': format_significance(p_values[2]),\n",
    "                'nll': res.fun,\n",
    "                'bic': calculate_bic(res.fun, 3, len(choices)),\n",
    "                'n_trials': len(choices)\n",
    "            })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ==========================================\n",
    "# Main Execution with Statistics\n",
    "# ==========================================\n",
    "\n",
    "# Fit all models\n",
    "df_standard_rl_stats = fit_robust_rl_model_with_stats(df_master)\n",
    "df_pt_stats = fit_robust_pt_model_with_stats(df_master)\n",
    "df_rl_pt_stats = fit_rl_pt_with_stats(df_master)\n",
    "df_hybrid_stats = fit_hybrid_likeability_with_stats(df_master)\n",
    "df_perseveration_stats = fit_perseveration_rl_with_stats(df_master)\n",
    "\n",
    "# ==========================================\n",
    "# Generate Summary Tables\n",
    "# ==========================================\n",
    "\n",
    "def create_summary_table(df, model_name, param_names):\n",
    "    \"\"\"Create a publication-ready summary table\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Calculate aggregate statistics\n",
    "    summary_rows = []\n",
    "    \n",
    "    for param in param_names:\n",
    "        mean_val = df[param].mean()\n",
    "        se_col = f\"{param}_se\"\n",
    "        \n",
    "        # Aggregate SE using formula: SE_aggregate = sqrt(mean(SE^2))\n",
    "        agg_se = np.sqrt((df[se_col]**2).mean())\n",
    "        \n",
    "        # Test if aggregate mean is different from 0\n",
    "        z_score = mean_val / agg_se\n",
    "        p_value = 2 * (1 - norm.cdf(np.abs(z_score)))\n",
    "        \n",
    "        summary_rows.append({\n",
    "            'Parameter': param,\n",
    "            'Mean': mean_val,\n",
    "            'SE': agg_se,\n",
    "            'z': z_score,\n",
    "            'P': p_value,\n",
    "            'Sig': format_significance(p_value)\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    \n",
    "    # Format for display\n",
    "    print(summary_df.to_string(index=False))\n",
    "    print(f\"\\nN subjects: {len(df)}\")\n",
    "    print(f\"Mean BIC: {df['bic'].mean():.2f}\")\n",
    "    print(f\"Mean NLL: {df['nll'].mean():.2f}\")\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "# Generate summary tables for each model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary_rl = create_summary_table(df_standard_rl_stats, \"Standard RL\", ['alpha', 'beta'])\n",
    "summary_pt = create_summary_table(df_pt_stats, \"Static Prospect Theory\", ['alpha', 'gamma', 'beta'])\n",
    "summary_rl_pt = create_summary_table(df_rl_pt_stats, \"RL + Prospect Theory\", ['alpha', 'beta', 'lambda'])\n",
    "summary_hybrid = create_summary_table(df_hybrid_stats, \"Hybrid RL + Likeability\", ['alpha', 'beta', 'omega'])\n",
    "summary_perseveration = create_summary_table(df_perseveration_stats, \"RL + Perseveration\", ['alpha', 'beta', 'kappa'])\n",
    "\n",
    "# ==========================================\n",
    "# Export Results\n",
    "# ==========================================\n",
    "\n",
    "# Save detailed results\n",
    "# df_standard_rl_stats.to_csv('model_results_rl_with_stats.csv', index=False)\n",
    "# df_pt_stats.to_csv('model_results_pt_with_stats.csv', index=False)\n",
    "# df_rl_pt_stats.to_csv('model_results_rl_pt_with_stats.csv', index=False)\n",
    "# df_hybrid_stats.to_csv('model_results_hybrid_with_stats.csv', index=False)\n",
    "# df_perseveration_stats.to_csv('model_results_perseveration_with_stats.csv', index=False)\n",
    "\n",
    "# # Save summary tables\n",
    "# with pd.ExcelWriter('model_summary_statistics.xlsx') as writer:\n",
    "#     summary_rl.to_excel(writer, sheet_name='RL', index=False)\n",
    "#     summary_pt.to_excel(writer, sheet_name='PT', index=False)\n",
    "#     summary_rl_pt.to_excel(writer, sheet_name='RL_PT', index=False)\n",
    "#     summary_hybrid.to_excel(writer, sheet_name='Hybrid', index=False)\n",
    "#     summary_perseveration.to_excel(writer, sheet_name='Perseveration', index=False)\n",
    "\n",
    "summary_rl.to_csv('statistics/summary_rl.csv', index=False)\n",
    "summary_pt.to_csv('statistics/summary_pt.csv', index=False)\n",
    "summary_rl_pt.to_csv('statistics/summary_rl_pt.csv', index=False)\n",
    "summary_hybrid.to_csv('statistics/summary_hybrid.csv', index=False)\n",
    "summary_perseveration.to_csv('statistics/summary_perseveration.csv', index=False)\n",
    "\n",
    "print(\"\\n✓ Results saved to CSV and Excel files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901ec28d-fbbf-4599-a8d5-b7fec286a6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM CHOICE SIMULATION & MODEL FITTING\n",
      "============================================================\n",
      "Loaded 759 rows, 19 subjects\n",
      "\n",
      "✓ Simulated 40 random choices (Q21-Q60) for 1 virtual subject\n",
      "✓ Choice distribution: [10  8 10 12]\n",
      "\n",
      "============================================================\n",
      "FITTING MODELS TO RANDOM DATA\n",
      "============================================================\n",
      "\n",
      "Fitting: Standard RL Model (Random Data)...\n",
      "Fitting: RL + Prospect Theory (Random Data)...\n",
      "Fitting: Static PT Model (Random Data)...\n",
      "Fitting: Hybrid RL + Likeability (Random Data)...\n",
      "Fitting: RL with Perseveration (Random Data)...\n",
      "\n",
      "============================================================\n",
      "SAVING RESULTS\n",
      "============================================================\n",
      "✓ Saved: random_bic_standard_rl.csv\n",
      "✓ Saved: random_bic_rl_pt.csv\n",
      "✓ Saved: random_bic_static_pt.csv\n",
      "✓ Saved: random_bic_hybrid_likeability.csv\n",
      "✓ Saved: random_bic_perseveration_rl.csv\n",
      "\n",
      "============================================================\n",
      "SUMMARY: Random BIC Values\n",
      "============================================================\n",
      "\n",
      "Standard RL:\n",
      "  Mean BIC: 117.37 ± nan\n",
      "\n",
      "RL + PT:\n",
      "  Mean BIC: 120.68 ± nan\n",
      "\n",
      "Static PT:\n",
      "  Mean BIC: 121.54 ± nan\n",
      "\n",
      "Hybrid RL + Likeability:\n",
      "  Mean BIC: 120.84 ± nan\n",
      "\n",
      "RL + Perseveration:\n",
      "  Mean BIC: 119.12 ± nan\n",
      "\n",
      "============================================================\n",
      "COMPLETE!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "############################################################Calculate Random BIC Values for Three Models by Simulation\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# ==========================================\n",
    "# HELPER FUNCTIONS (from your original code)\n",
    "# ==========================================\n",
    "\n",
    "def softmax(x, beta=1.0):\n",
    "    \"\"\"Softmax function with stability adjustment.\"\"\"\n",
    "    ex = np.exp(beta * (x - np.max(x)))\n",
    "    return ex / ex.sum()\n",
    "\n",
    "def calculate_bic(nll, n_params, n_observations):\n",
    "    \"\"\"Calculate Bayesian Information Criterion (BIC)\"\"\"\n",
    "    return 2 * nll + n_params * np.log(n_observations)\n",
    "\n",
    "def prepare_arrays_robust(sub_df):\n",
    "    \"\"\"Data preprocessing: ensure no NaN values, extract choice and reward.\"\"\"\n",
    "    choice_col = 'category_idx' if 'category_idx' in sub_df.columns else 'choice'\n",
    "    reward_col = 'reward'\n",
    "    \n",
    "    mask = ~sub_df[choice_col].isna() & ~sub_df[reward_col].isna()\n",
    "    clean_df = sub_df[mask].copy()\n",
    "    \n",
    "    choices = clean_df[choice_col].astype(int).values\n",
    "    rewards = clean_df[reward_col].astype(float).values\n",
    "    \n",
    "    if choices.min() == 0:\n",
    "        choices = choices + 1\n",
    "        \n",
    "    return choices, rewards\n",
    "\n",
    "# ==========================================\n",
    "# RANDOM CHOICE SIMULATION\n",
    "# ==========================================\n",
    "\n",
    "def simulate_random_choices(df_original, seed=42):\n",
    "    \"\"\"\n",
    "    Simulate a single random responder with 40 trials (Q21-Q60).\n",
    "    Creates random choices for each question, ignoring subject structure.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_original : DataFrame\n",
    "        Original experimental data (used only to get reward structure)\n",
    "    seed : int\n",
    "        Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    df_random : DataFrame\n",
    "        Simulated data with 40 random choices (one virtual subject)\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Get unique question information from original data\n",
    "    # Assuming questions 21-60 (40 questions total)\n",
    "    questions = range(21, 61)\n",
    "    \n",
    "    # Create a mapping of question_id to category rewards\n",
    "    # Using the first occurrence of each question to get reward structure\n",
    "    question_rewards = {}\n",
    "    for qid in questions:\n",
    "        q_data = df_original[df_original['question_id'] == qid]\n",
    "        if len(q_data) > 0:\n",
    "            # Get rewards for each category (1-4) for this question\n",
    "            rewards_by_cat = {}\n",
    "            for cat in [1, 2, 3, 4]:\n",
    "                cat_data = q_data[q_data['category_idx'] == cat]\n",
    "                if len(cat_data) > 0:\n",
    "                    rewards_by_cat[cat] = cat_data['reward'].iloc[0]\n",
    "            question_rewards[qid] = rewards_by_cat\n",
    "    \n",
    "    # Generate 40 random choices (one per question)\n",
    "    random_choices = np.random.randint(1, 5, size=40)\n",
    "    \n",
    "    # Create dataframe for single random subject\n",
    "    data = []\n",
    "    for i, qid in enumerate(questions):\n",
    "        choice = random_choices[i]\n",
    "        # Get reward for chosen category\n",
    "        reward = question_rewards.get(qid, {}).get(choice, 2.5)  # default 2.5 if missing\n",
    "        \n",
    "        # Get likeability data from original (use first subject's data as placeholder)\n",
    "        sample_row = df_original[df_original['question_id'] == qid].iloc[0]\n",
    "        \n",
    "        data.append({\n",
    "            'subject_id': 999,  # Virtual random subject ID\n",
    "            'trial': i + 1,\n",
    "            'question_id': qid,\n",
    "            'category_idx': choice,\n",
    "            'reward': reward,\n",
    "            'valid_preference_data': True,\n",
    "            'prev_reward': 0 if i == 0 else data[i-1]['reward'],\n",
    "            'prev_choice': 0 if i == 0 else data[i-1]['category_idx'],\n",
    "            'like_cat1': sample_row['like_cat1'],\n",
    "            'like_cat2': sample_row['like_cat2'],\n",
    "            'like_cat3': sample_row['like_cat3'],\n",
    "            'like_cat4': sample_row['like_cat4'],\n",
    "            'score_cat1': sample_row['score_cat1'],\n",
    "            'score_cat2': sample_row['score_cat2'],\n",
    "            'score_cat3': sample_row['score_cat3'],\n",
    "            'score_cat4': sample_row['score_cat4']\n",
    "        })\n",
    "    \n",
    "    df_random = pd.DataFrame(data)\n",
    "    \n",
    "    print(f\"✓ Simulated 40 random choices (Q21-Q60) for 1 virtual subject\")\n",
    "    print(f\"✓ Choice distribution: {np.bincount(random_choices)[1:]}\")\n",
    "    \n",
    "    return df_random\n",
    "\n",
    "# ==========================================\n",
    "# MODEL FITTING FUNCTIONS (unchanged structure)\n",
    "# ==========================================\n",
    "\n",
    "# 1. Standard RL Model\n",
    "def negloglik_rl_robust(params, choices, rewards, n_options=4, q0=2.5):\n",
    "    alpha, logbeta = params\n",
    "    if not (0 <= alpha <= 1):\n",
    "        return 1e9\n",
    "        \n",
    "    beta = np.exp(logbeta)\n",
    "    Q = np.ones(n_options) * q0\n",
    "    nll = 0.0\n",
    "    \n",
    "    for c, r in zip(choices, rewards):\n",
    "        c_idx = c - 1\n",
    "        probs = softmax(Q, beta=beta)\n",
    "        p = probs[c_idx]\n",
    "        p = max(p, 1e-12)\n",
    "        nll -= np.log(p)\n",
    "        Q[c_idx] = Q[c_idx] + alpha * (r - Q[c_idx])\n",
    "        \n",
    "    return nll\n",
    "\n",
    "def fit_robust_rl_model(df):\n",
    "    print(\"Fitting: Standard RL Model (Random Data)...\")\n",
    "    results = []\n",
    "    user_col = 'subject_id' if 'subject_id' in df.columns else 'user'\n",
    "    \n",
    "    for sub_id, sub_df in df.groupby(user_col):\n",
    "        choices, rewards = prepare_arrays_robust(sub_df)\n",
    "        if len(choices) < 5:\n",
    "            continue\n",
    "\n",
    "        x0 = np.array([0.3, np.log(1.0)])\n",
    "        bounds = [(0.0, 1.0), (np.log(1e-3), np.log(1e3))]\n",
    "        \n",
    "        res = minimize(\n",
    "            lambda x: negloglik_rl_robust(x, choices, rewards), \n",
    "            x0, bounds=bounds, method='L-BFGS-B'\n",
    "        )\n",
    "        \n",
    "        if res.success:\n",
    "            alpha = res.x[0]\n",
    "            beta = float(np.exp(res.x[1]))\n",
    "            nll = res.fun\n",
    "        else:\n",
    "            alpha, beta, nll = np.nan, np.nan, np.nan\n",
    "            \n",
    "        bic = calculate_bic(nll, 2, len(choices)) if not np.isnan(nll) else np.nan\n",
    "        \n",
    "        results.append({\n",
    "            'subject_id': sub_id,\n",
    "            'alpha': alpha,\n",
    "            'beta': beta,\n",
    "            'nll': nll,\n",
    "            'bic': bic\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 2. RL + Prospect Theory\n",
    "def fit_rl_pt(df):\n",
    "    print(\"Fitting: RL + Prospect Theory (Random Data)...\")\n",
    "    results = []\n",
    "    GAMMA = 0.8\n",
    "    REF_POINT = 2.5\n",
    "    \n",
    "    def get_nll_robust(params, choices, rewards):\n",
    "        alpha, log_beta, log_lamb = params\n",
    "        if not (0 <= alpha <= 1):\n",
    "            return 1e9\n",
    "        \n",
    "        beta = np.exp(log_beta)\n",
    "        lamb = np.exp(log_lamb)\n",
    "        q_values = np.full(4, 2.5)\n",
    "        nll = 0.0\n",
    "        \n",
    "        for c, r in zip(choices, rewards):\n",
    "            c_idx = int(c) - 1\n",
    "            probs = softmax(q_values, beta=beta)\n",
    "            nll -= np.log(max(probs[c_idx], 1e-12))\n",
    "            \n",
    "            utility = (r - REF_POINT)**GAMMA if r >= REF_POINT else -lamb * ((REF_POINT - r)**GAMMA)\n",
    "            q_values[c_idx] += alpha * (utility - q_values[c_idx])\n",
    "        return nll\n",
    "\n",
    "    for sub_id, sub_df in df.groupby('subject_id'):\n",
    "        choices, rewards = prepare_arrays_robust(sub_df)\n",
    "        if len(choices) < 5:\n",
    "            continue\n",
    "        \n",
    "        x0 = [0.5, np.log(2.0), np.log(1.0)]\n",
    "        bounds = [(0, 1), (np.log(1e-3), np.log(1e3)), (np.log(1e-3), np.log(1e2))]\n",
    "        \n",
    "        res = minimize(lambda x: get_nll_robust(x, choices, rewards), x0, bounds=bounds, method='L-BFGS-B')\n",
    "        \n",
    "        if res.success:\n",
    "            results.append({\n",
    "                'subject_id': sub_id,\n",
    "                'alpha': res.x[0],\n",
    "                'beta': np.exp(res.x[1]),\n",
    "                'lambda': np.exp(res.x[2]),\n",
    "                'nll': res.fun,\n",
    "                'bic': calculate_bic(res.fun, 3, len(choices))\n",
    "            })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 3. Static PT Model\n",
    "def compute_empirical_category_distributions(df):\n",
    "    dists = {}\n",
    "    cat_col = 'category_idx' if 'category_idx' in df.columns else 'cat'\n",
    "    if df[cat_col].min() == 0:\n",
    "        df = df.copy()\n",
    "        df[cat_col] = df[cat_col] + 1\n",
    "    \n",
    "    for cat in [1, 2, 3, 4]:\n",
    "        vals = df[df[cat_col] == cat]['reward'].dropna().values\n",
    "        if len(vals) == 0:\n",
    "            dists[cat] = (np.array([0.0, 1.0]), np.array([0.0, 0.0]))\n",
    "        else:\n",
    "            unique, counts = np.unique(vals, return_counts=True)\n",
    "            probs = counts / counts.sum()\n",
    "            dists[cat] = (unique, probs)\n",
    "    return dists\n",
    "\n",
    "def prelec_weight(p, gamma):\n",
    "    p = np.clip(p, 1e-12, 1.0)\n",
    "    return np.exp(-(-np.log(p)) ** gamma)\n",
    "\n",
    "def subjective_EV_for_category(cat, alpha_val, gamma_val, category_dists):\n",
    "    outcomes, probs = category_dists[cat]\n",
    "    u = outcomes ** alpha_val\n",
    "    w = prelec_weight(probs, gamma_val)\n",
    "    if w.sum() == 0:\n",
    "        w = probs\n",
    "    else:\n",
    "        w = w / w.sum()\n",
    "    return np.sum(w * u)\n",
    "\n",
    "def negloglik_pt_robust(params, choices, category_dists):\n",
    "    log_alpha, log_gamma, log_beta = params\n",
    "    alpha_val = np.exp(log_alpha)\n",
    "    gamma_val = np.exp(log_gamma)\n",
    "    beta = np.exp(log_beta)\n",
    "    \n",
    "    sEV = np.array([subjective_EV_for_category(cat, alpha_val, gamma_val, category_dists) \n",
    "                    for cat in [1, 2, 3, 4]])\n",
    "    \n",
    "    nll = 0.0\n",
    "    for c in choices:\n",
    "        c_idx = c - 1\n",
    "        probs = softmax(sEV, beta=beta)\n",
    "        p = probs[c_idx]\n",
    "        p = max(p, 1e-12)\n",
    "        nll -= np.log(p)\n",
    "    return nll\n",
    "\n",
    "def fit_robust_pt_model(df):\n",
    "    print(\"Fitting: Static PT Model (Random Data)...\")\n",
    "    results = []\n",
    "    category_dists = compute_empirical_category_distributions(df)\n",
    "    user_col = 'subject_id' if 'subject_id' in df.columns else 'user'\n",
    "    \n",
    "    for sub_id, sub_df in df.groupby(user_col):\n",
    "        choices, _ = prepare_arrays_robust(sub_df)\n",
    "        if len(choices) < 5:\n",
    "            continue\n",
    "            \n",
    "        x0 = np.array([np.log(0.9), np.log(0.9), np.log(1.0)])\n",
    "        bounds = [\n",
    "            (np.log(1e-2), np.log(5.0)), \n",
    "            (np.log(1e-2), np.log(5.0)), \n",
    "            (np.log(1e-3), np.log(1e3))\n",
    "        ]\n",
    "        \n",
    "        res = minimize(\n",
    "            lambda x: negloglik_pt_robust(x, choices, category_dists),\n",
    "            x0, bounds=bounds, method='L-BFGS-B'\n",
    "        )\n",
    "        \n",
    "        if res.success:\n",
    "            alpha = float(np.exp(res.x[0]))\n",
    "            gamma = float(np.exp(res.x[1]))\n",
    "            beta = float(np.exp(res.x[2]))\n",
    "            nll = res.fun\n",
    "        else:\n",
    "            alpha, gamma, beta, nll = np.nan, np.nan, np.nan, np.nan\n",
    "            \n",
    "        bic = calculate_bic(nll, 3, len(choices)) if not np.isnan(nll) else np.nan\n",
    "        \n",
    "        results.append({\n",
    "            'subject_id': sub_id,\n",
    "            'alpha': alpha,\n",
    "            'gamma': gamma,\n",
    "            'beta': beta,\n",
    "            'nll': nll,\n",
    "            'bic': bic\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 4. Hybrid RL + Likeability\n",
    "def fit_hybrid_likeability(df):\n",
    "    print(\"Fitting: Hybrid RL + Likeability (Random Data)...\")\n",
    "    \n",
    "    df_std = df.copy()\n",
    "    like_cols = ['like_cat1', 'like_cat2', 'like_cat3', 'like_cat4']\n",
    "    for sub_id, group in df_std.groupby('subject_id'):\n",
    "        vals = group[like_cols].values.flatten()\n",
    "        std_val = np.nanstd(vals)\n",
    "        if std_val == 0:\n",
    "            std_val = 1\n",
    "        df_std.loc[df_std['subject_id'] == sub_id, like_cols] = (group[like_cols] - np.nanmean(vals)) / std_val\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    def get_nll_robust(params, choices, rewards, like_matrix):\n",
    "        alpha, log_beta, omega = params\n",
    "        if not (0 <= alpha <= 1):\n",
    "            return 1e9\n",
    "        \n",
    "        beta = np.exp(log_beta)\n",
    "        q_values = np.full(4, 2.5)\n",
    "        nll = 0.0\n",
    "        \n",
    "        for i, (c, r) in enumerate(zip(choices, rewards)):\n",
    "            c_idx = int(c) - 1\n",
    "            likes = like_matrix[i]\n",
    "            v_values = (beta * q_values) + (omega * likes)\n",
    "            probs = softmax(v_values, beta=1.0)\n",
    "            nll -= np.log(max(probs[c_idx], 1e-12))\n",
    "            q_values[c_idx] += alpha * (r - q_values[c_idx])\n",
    "        return nll\n",
    "\n",
    "    for sub_id, sub_df in df_std.groupby('subject_id'):\n",
    "        choices, rewards = prepare_arrays_robust(sub_df)\n",
    "        if len(choices) < 5:\n",
    "            continue\n",
    "        \n",
    "        mask = ~sub_df['category_idx'].isna() & ~sub_df['reward'].isna()\n",
    "        like_matrix = sub_df.loc[mask, like_cols].values\n",
    "        \n",
    "        x0 = [0.5, np.log(2.0), 0.5]\n",
    "        bounds = [(0, 1), (np.log(1e-3), np.log(1e3)), (-10, 10)]\n",
    "        \n",
    "        res = minimize(lambda x: get_nll_robust(x, choices, rewards, like_matrix), x0, bounds=bounds, method='L-BFGS-B')\n",
    "        \n",
    "        if res.success:\n",
    "            results.append({\n",
    "                'subject_id': sub_id,\n",
    "                'alpha': res.x[0],\n",
    "                'beta': np.exp(res.x[1]),\n",
    "                'omega': res.x[2],\n",
    "                'nll': res.fun,\n",
    "                'bic': calculate_bic(res.fun, 3, len(choices))\n",
    "            })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 5. RL with Perseveration\n",
    "def fit_perseveration_rl(df):\n",
    "    print(\"Fitting: RL with Perseveration (Random Data)...\")\n",
    "    results = []\n",
    "    \n",
    "    def get_nll_robust(params, choices, rewards):\n",
    "        alpha, log_beta, kappa = params\n",
    "        if not (0 <= alpha <= 1):\n",
    "            return 1e9\n",
    "        \n",
    "        beta = np.exp(log_beta)\n",
    "        q_values = np.full(4, 2.5)\n",
    "        nll = 0.0\n",
    "        prev_choice = -1\n",
    "        \n",
    "        for c, r in zip(choices, rewards):\n",
    "            c_idx = int(c) - 1\n",
    "            v_values = beta * q_values\n",
    "            if prev_choice != -1:\n",
    "                v_values[prev_choice] += kappa\n",
    "            \n",
    "            probs = softmax(v_values, beta=1.0)\n",
    "            nll -= np.log(max(probs[c_idx], 1e-12))\n",
    "            q_values[c_idx] += alpha * (r - q_values[c_idx])\n",
    "            prev_choice = c_idx\n",
    "        return nll\n",
    "\n",
    "    for sub_id, sub_df in df.groupby('subject_id'):\n",
    "        choices, rewards = prepare_arrays_robust(sub_df)\n",
    "        if len(choices) < 5:\n",
    "            continue\n",
    "        \n",
    "        x0 = [0.5, np.log(2.0), 0.5]\n",
    "        bounds = [(0, 1), (np.log(1e-3), np.log(1e3)), (-5, 5)]\n",
    "        \n",
    "        res = minimize(lambda x: get_nll_robust(x, choices, rewards), x0, bounds=bounds, method='L-BFGS-B')\n",
    "        \n",
    "        if res.success:\n",
    "            results.append({\n",
    "                'subject_id': sub_id,\n",
    "                'alpha': res.x[0],\n",
    "                'beta': np.exp(res.x[1]),\n",
    "                'kappa': res.x[2],\n",
    "                'nll': res.fun,\n",
    "                'bic': calculate_bic(res.fun, 3, len(choices))\n",
    "            })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ==========================================\n",
    "# MAIN EXECUTION PIPELINE\n",
    "# ==========================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your original data\n",
    "    df_master = pd.read_csv('02_Master_df.txt')\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"RANDOM CHOICE SIMULATION & MODEL FITTING\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Loaded {len(df_master)} rows, {df_master['subject_id'].nunique()} subjects\\n\")\n",
    "    \n",
    "    # Step 1: Simulate random choices (40 trials, Q21-Q60)\n",
    "    df_random = simulate_random_choices(df_master, seed=42)\n",
    "    \n",
    "    # Step 2: Fit all models to random data\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FITTING MODELS TO RANDOM DATA\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    df_random_rl = fit_robust_rl_model(df_random)\n",
    "    df_random_rl_pt = fit_rl_pt(df_random)\n",
    "    df_random_pt = fit_robust_pt_model(df_random)\n",
    "    df_random_hybrid = fit_hybrid_likeability(df_random)\n",
    "    df_random_perseveration = fit_perseveration_rl(df_random)\n",
    "    \n",
    "    # Step 3: Save results to separate files\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SAVING RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    df_random_rl.to_csv('random_bic_standard_rl.csv', index=False)\n",
    "    print(\"✓ Saved: random_bic_standard_rl.csv\")\n",
    "    \n",
    "    df_random_rl_pt.to_csv('random_bic_rl_pt.csv', index=False)\n",
    "    print(\"✓ Saved: random_bic_rl_pt.csv\")\n",
    "    \n",
    "    df_random_pt.to_csv('random_bic_static_pt.csv', index=False)\n",
    "    print(\"✓ Saved: random_bic_static_pt.csv\")\n",
    "    \n",
    "    df_random_hybrid.to_csv('random_bic_hybrid_likeability.csv', index=False)\n",
    "    print(\"✓ Saved: random_bic_hybrid_likeability.csv\")\n",
    "    \n",
    "    df_random_perseveration.to_csv('random_bic_perseveration_rl.csv', index=False)\n",
    "    print(\"✓ Saved: random_bic_perseveration_rl.csv\")\n",
    "    \n",
    "    # Step 4: Display summary statistics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SUMMARY: Random BIC Values\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nStandard RL:\")\n",
    "    print(f\"  Mean BIC: {df_random_rl['bic'].mean():.2f} ± {df_random_rl['bic'].std():.2f}\")\n",
    "    \n",
    "    print(f\"\\nRL + PT:\")\n",
    "    print(f\"  Mean BIC: {df_random_rl_pt['bic'].mean():.2f} ± {df_random_rl_pt['bic'].std():.2f}\")\n",
    "    \n",
    "    print(f\"\\nStatic PT:\")\n",
    "    print(f\"  Mean BIC: {df_random_pt['bic'].mean():.2f} ± {df_random_pt['bic'].std():.2f}\")\n",
    "    \n",
    "    print(f\"\\nHybrid RL + Likeability:\")\n",
    "    print(f\"  Mean BIC: {df_random_hybrid['bic'].mean():.2f} ± {df_random_hybrid['bic'].std():.2f}\")\n",
    "    \n",
    "    print(f\"\\nRL + Perseveration:\")\n",
    "    print(f\"  Mean BIC: {df_random_perseveration['bic'].mean():.2f} ± {df_random_perseveration['bic'].std():.2f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"COMPLETE!\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93935c39-2162-41a5-b5d0-dbcb1f0c6c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (scCube)",
   "language": "python",
   "name": "sccube"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
